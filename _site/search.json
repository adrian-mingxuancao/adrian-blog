[
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "",
    "text": "AlphaGenome is a deep learning model that processes 1 megabase (Mb) of DNA sequence to predict a broad range of functional genomic outputs at high resolution. Developed by Google DeepMind, AlphaGenome unifies multimodal genomic prediction, long-range sequence context, and single base-pair resolution into one framework. It generates 5,930 human (or 1,128 mouse) genome tracks covering 11 data modalities – including gene expression (RNA-seq, CAGE, PRO-cap), splicing (splice sites, splice site usage, splice junctions), chromatin accessibility (DNase, ATAC-seq), histone marks, transcription factor binding, and 3D chromatin contacts. Trained jointly on human and mouse genomes, AlphaGenome achieves or exceeds state-of-the-art performance on the vast majority of benchmarks, matching or outperforming the best available models on 24 out of 26 variant effect prediction tasks. In doing so, it addresses longstanding trade-offs in genome modeling by capturing both distal regulatory context and nucleotide-level detail, enabling more accurate predictions of how genetic variants influence gene regulation. This report provides a detailed overview of AlphaGenome’s methodology – including its architecture, training strategy, improvements over the earlier Enformer model, variant effect prediction performance across multiple modalities, and speculations on integrating AlphaGenome with genomic language models."
  },
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html#introduction",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html#introduction",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "",
    "text": "AlphaGenome is a deep learning model that processes 1 megabase (Mb) of DNA sequence to predict a broad range of functional genomic outputs at high resolution. Developed by Google DeepMind, AlphaGenome unifies multimodal genomic prediction, long-range sequence context, and single base-pair resolution into one framework. It generates 5,930 human (or 1,128 mouse) genome tracks covering 11 data modalities – including gene expression (RNA-seq, CAGE, PRO-cap), splicing (splice sites, splice site usage, splice junctions), chromatin accessibility (DNase, ATAC-seq), histone marks, transcription factor binding, and 3D chromatin contacts. Trained jointly on human and mouse genomes, AlphaGenome achieves or exceeds state-of-the-art performance on the vast majority of benchmarks, matching or outperforming the best available models on 24 out of 26 variant effect prediction tasks. In doing so, it addresses longstanding trade-offs in genome modeling by capturing both distal regulatory context and nucleotide-level detail, enabling more accurate predictions of how genetic variants influence gene regulation. This report provides a detailed overview of AlphaGenome’s methodology – including its architecture, training strategy, improvements over the earlier Enformer model, variant effect prediction performance across multiple modalities, and speculations on integrating AlphaGenome with genomic language models."
  },
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html#methodology",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html#methodology",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "Methodology",
    "text": "Methodology\n\nModel Architecture: U-Net Design with Transformers and Multi-Resolution Output\nU-Net–style Encoder–Decoder: AlphaGenome’s architecture follows a U-Net inspired design, consisting of an encoder that progressively downsamples the input sequence, a “Transformer Tower” that integrates long-range information, and a decoder that upsamples back to high resolution outputs. The encoder–decoder structure is similar to those in image segmentation (U-Net) but adapted for 1D genomic sequences. The sequence encoder uses multiple convolutional blocks and pooling to reduce the sequence length while increasing channel depth, extracting hierarchical features at increasing scales. Starting from 1 bp resolution with 768 channels, the encoder downsamples through 7 stages (with max-pooling by 2 at each stage) to a final 128 bp resolution latent representation with 1536 channels. Convolutional filters capture local sequence motifs (e.g. transcription factor binding sites, splice signals) needed for base-level precision. Residual connections (“skip” connections) from the encoder layers are carried into the decoder, as in U-Net, to preserve fine-grained spatial information. The sequence decoder upsamples the latent representation back toward higher resolutions, merging with encoder skip features to output predictions at multiple scales (including single-nucleotide resolution for certain tracks). This multi-resolution design allows AlphaGenome to output different genomic tracks at the appropriate resolution for each assay – for example, base-pair resolution for splice site usage or transcription start sites, and binned resolution for broader signals like contacts.\nTransformer Layers for Long-Range Context: Between encoder and decoder, AlphaGenome inserts a stack of Transformer blocks (the “Transformer Tower”) operating on the 128 bp-resolution encoded sequence. Nine transformer layers model coarse but long-range dependencies across the entire 1 Mb input, such as distal enhancer–promoter interactions or coordinated chromatin state changes. These transformers use multi-head self-attention to allow any position in the 1 Mb sequence to attend to any other, capturing genomic interactions spanning hundreds of kilobases. To manage the computational load of such a long sequence, AlphaGenome employs multi-query attention (multiple query heads but shared key/value) to reduce memory, and applies Rotary Positional Embeddings (RoPE) for encoding positional information over 8192 positions (which correspond to 1,048,576 bp at 128 bp resolution). Additionally, attention logits are stabilized with techniques like soft clipping (constraining values to [-5,5]) before softmax. Notably, AlphaGenome introduces a pairwise interaction bias in the attention: every second transformer block is preceded by an update to a 2D pairwise representation (of size 512×512, representing the 1 Mb region at 2048 bp resolution) that captures spatial contacts between sequence segments. This pairwise matrix (128 channels) is analogous to the approach in AlphaFold, and is used both to produce 3D chromatin contact map predictions and as an attention bias added into the Transformer’s self-attention weights. By injecting this learned pairwise contact bias into the attention layers, the model can more easily learn long-range chromatin loops and interactions while maintaining single-base sensitivity. The final output of the transformer tower is thus a context-enriched sequence embedding (still at 128 bp resolution) along with a pairwise interaction matrix representing coarse chromatin contacts.\nSequence Parallelism for 1 Mb Input: Handling a 1,048,576 bp input with such a deep model is computationally challenging. AlphaGenome leverages sequence parallelism across multiple hardware devices to make this feasible. In practice, the 1 Mb sequence is split into 8 chunks (~131 kb each) which are processed in parallel on 8 interconnected TPUv3 cores, with synchronized communication in the transformer layers. This allows true 1 Mb context to be processed with base-pair resolution output, something that would be memory-prohibitive on a single device. The model totals ~450 million parameters distributed across components (≈20% in encoder conv layers, 28% in transformers, 15% in pairwise/contact blocks, 25% in decoder, 12% in output heads). Despite its scale, the sequence-parallel design enables efficient inference: the final distilled model runs a variant effect prediction in under one second on a modern GPU.\nMulti-Scale Outputs and Heads: AlphaGenome produces predictions at multiple output resolutions to suit different assay types. The task-specific output heads are linear layers or small networks that take the decoder’s sequence embeddings and produce the final track values. For most genomic tracks (e.g. epigenomic signals, accessibility, basewise expression coverage), the model outputs a continuous track of predicted signal per base or per small bin, achieved by upsampling the decoder embeddings back to 1 bp resolution and applying a linear transformation. Some outputs are naturally lower-resolution (for instance, histone ChIP-seq might be averaged in bins, or 3D contacts are at 2048 bp bins), and these heads use the appropriate latent scale. Importantly, AlphaGenome includes a novel mechanism for splice junction count prediction, which is not generated by a single-position linear head. Instead, predicting a junction (connecting a donor and acceptor site) requires pairing two distant sequence positions. AlphaGenome addresses this by a separate junction module that computes an interaction between the 1D embeddings of predicted donor and acceptor sites to produce a count for that specific exon-exon junction. In essence, it identifies all candidate donor/acceptor pairs from the decoder’s 1 bp resolution embeddings and assigns each a score, enabling prediction of splice junction read counts (and even novel exon connections) that standard sequence models could not directly output. This is a unique architectural feature of AlphaGenome, allowing it to model splicing outcomes at the level of individual introns (splice junctions) in addition to per-site usage. Overall, by combining convolutional local feature extractors, transformers for global context, and a U-net decoder for high-resolution reconstruction, AlphaGenome’s architecture is able to capture patterns ranging from transcription factor binding motifs to multi-kilobase enhancer looping, all within one model.\n\n\nTraining Strategy: Two-Stage Pre-training and Distillation\nTraining AlphaGenome to robustly predict genome-wide profiles and variant effects required a carefully designed two-stage training process. The authors employed a pre-training stage on experimental data followed by a distillation stage to produce a single efficient model for variant effect prediction.\nStage 1 – Cross-Validated Pre-training on Experimental Data: In the first stage, AlphaGenome was trained directly on the vast compendium of experimental genomics data (profiles of chromatin marks, RNA-seq coverage, etc.) using a form of cross-validation training. The genome was split into four folds, each comprising 25% of the human (and mouse) reference genome segments. Fold-specific models were trained on 3 out of 4 folds (75% of the genome) and validated on the held-out fold. This yields four independent teacher models, each having seen most of the genome but tested on a unique held-out portion. In addition, a separate set of “all-folds” teacher models were trained on all available data (100% of the genome intervals) to maximize use of training data. These all-folds models represent what the model can achieve when not holding out any part of the genome, and effectively serve as an ensemble of experts that have seen the full diversity of sequences. Throughout pre-training, data augmentation was applied: input 1 Mb sequences were randomly shifted or reverse-complemented to augment context and reduce positional biases. The model was trained to minimize error between predicted tracks and actual experimental tracks, producing high-fidelity genome track predictors. By the end of this stage, AlphaGenome had learned to accurately predict functional genomics tracks on sequence segments it had never seen (testing on held-out folds) – establishing its strong generalization for genome-wide prediction. Notably, as a fully multimodal model, it was simultaneously learning splicing patterns, gene expression levels, chromatin signals, and more, across thousands of output channels.\nStage 2 – Distillation into a Single Student Model: While the fold-specific models demonstrated performance, using them for variant effect prediction would require ensembling or making multiple predictions per variant (one for each model). Instead, AlphaGenome’s second stage produces one unified model via knowledge distillation. The all-folds teacher models (from stage 1) are frozen, and a single student model (with the same architecture) is trained to mimic the teachers’ outputs on new sequences. In this stage, the student takes augmented input sequences (including simulated variant perturbations) and must predict the outputs that the ensemble of teachers would have produced. Essentially, the student is learning a smoothed, averaged representation of the multiple teacher models. This approach has two key benefits: (1) The student model ends up more robust and accurate on variant effect prediction than any single direct model. Distillation has been shown to improve robustness and VEP accuracy in prior work, likely because the student learns to generalize the consensus of many teachers, reducing overfitting to idiosyncrasies. (2) The single student is computationally efficient, replacing what would otherwise be an ensemble of 4+ large models. The resulting distilled AlphaGenome can score a variant’s effects on all modalities with one forward pass in under one second on modern hardware. This is crucial for practical use in scanning millions of variants. During distillation, random sequence augmentations and even mutational perturbations were applied to the input, so the student learns to handle variants implicitly. By learning from the teacher ensemble’s predictions (which have effectively seen the entire genome), the student generalizes well even to variants in novel sequences.\nImplications for Variant Effect Prediction: The two-stage strategy means that AlphaGenome’s final model is not directly trained on ground-truth variant effect labels, but rather inherits its variant-scoring ability from the accuracy of the teacher models on reference genome tracks. Because the student sees mutated sequences during distillation and must predict the teachers’ outputs for both reference and altered sequences, it effectively learns to translate sequence changes into output differences. This distilled model proved to be exceptionally strong in variant effect prediction tasks, outperforming direct training in many cases. The authors note that ensembling across several independently trained models can improve variant effect performance, but their distilled single model achieves comparable or better accuracy without ensembling. In summary, the training pipeline first teaches AlphaGenome what patterns to predict (by fitting experimental data), and then teaches it how to efficiently approximate an ensemble of those predictors in one network – yielding a model that is both powerful and practical for scoring variants.\n\n\nComparison to Enformer: Context Length, Resolution, and Directional Prediction\nImproving on Enformer’s Context vs. Resolution Trade-off: One of AlphaGenome’s key achievements is combining long-range genomic context with single-base resolution outputs, improving upon limitations of the Enformer model. Enformer (Avsec et al., 2021) was an earlier transformer-based model that processed ~200 kb of DNA and predicted epigenomic tracks at a fixed 128 bp output bin size. This meant Enformer could capture distal enhancers but only produced low-resolution tracks, blurring fine features like splice sites. AlphaGenome extends the input length to 1 Mb (5× longer) and outputs many tracks at 1 bp resolution, thanks to its U-Net decoder design. By downsampling and then upsampling with skip connections, AlphaGenome preserves nucleotide-level information despite the large receptive field. In contrast to Enformer’s 128 bp discretization, AlphaGenome can pinpoint effects at individual bases (e.g. exact splice donor positions or transcription start sites) while still modeling contacts and enhancer–promoter interactions hundreds of kilobases away. This effectively eliminates the trade-off: AlphaGenome captures long-range interactions without sacrificing resolution. As noted in the paper, previous models like Enformer or its successor Borzoi had to reduce resolution (to 128 bp or even 32 bp bins) to handle &gt;200 kb sequences, missing fine regulatory elements. AlphaGenome’s architecture resolves this by using sequence parallelism and a multi-scale decoder, achieving both breadth and detail in predictions. A direct head-to-head benchmark confirmed this improvement: when retrained to predict Enformer’s own track targets, AlphaGenome attained higher accuracy than Enformer even on Enformer’s task, despite using the full 1 Mb input and base-level features. In other words, AlphaGenome can do what Enformer did, only better – plus much more. Figure 1 of the AlphaGenome paper summarizes that across various genome-wide prediction tasks (covering RNA-seq, chromatin marks, etc.), AlphaGenome had performance gains in the range of +5% to +40% relative to the best prior models, Enformer included. For instance, it improved Pearson correlation for cell-type-specific gene expression by +17.4% over Borzoi (a model that itself builds on Enformer). These results demonstrate that by addressing Enformer’s limitations – extending context and sharpening resolution – AlphaGenome yields more accurate predictions of genomic function.\nAddressing Variant Effect Directionality: Another notable shortcoming of Enformer was its difficulty in predicting the direction of variant effects (i.e. whether a mutation increases or decreases a functional readout). Enformer could predict changes in track intensity, but often struggled to correctly classify the sign of effect, especially for gene expression QTLs. AlphaGenome explicitly tackles this directional prediction problem and shows marked improvements. In evaluations on eQTLs (expression quantitative trait loci), AlphaGenome was able to predict not just the magnitude of expression change but also the sign (direction) of the  with significantly better accuracy than previous models. For example, compared to Borzoi (the prior state-of-the-art and an improved Enformer-like model), AlphaGenome improved the area under ROC for predicting eQTL effect direction from 0.75 to 0.80 (a substantial +5% increase in classification performance). It also achieved a higher Spearman rho (0.49 vs 0.39) for correlating predicted vs observed effect sizes (magnitudes). These gains indicate that AlphaGenome can more reliably tell if a variant will up-regulate or down-regulate a gene’s expression, which Enformer and others struggled with. The improvement comes from multiple factors: the multimodal outputs (AlphaGenome predicts downstream consequences on many tracks, providing richer clues to infer direction), the distillation training (which may smooth out noise and make the model more confident in sign), and possibly architectural changes like basepair-resolution outputs that capture subtle asymmetric effects. As a concrete example, AlphaGenome’s paper highlights a variant near the TAL1 oncogene where Enformer-based scoring had difficulty, but AlphaGenome clearly predicted that the mutation activated an enhancer to increase TAL1 expression. More generally, AlphaGenome was shown to recover far more true positive eQTLs at high precision when requiring correct direction: at 90% predicted sign accuracy, it captured 2× more eQTLs than the previous model (41% vs 19% of variants). This indicates that researchers can now filter variant hits by predicted direction with much greater confidence. In summary, AlphaGenome largely overcomes Enformer’s directional limitation by providing a model that not only predicts the magnitude of molecular changes caused by a variant but also correctly infers the polarity of the effect (gain or loss of function) across modalities. This is a critical advancement for variant interpretation, as knowing how a variant perturbs a gene or element (increasing vs decreasing activity) is key to linking variants to phenotypic outcomes."
  },
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html#variant-effect-prediction-across-modalities",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html#variant-effect-prediction-across-modalities",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "Variant Effect Prediction Across Modalities",
    "text": "Variant Effect Prediction Across Modalities\nAlphaGenome was evaluated on a comprehensive suite of 26 variant effect prediction (VEP) benchmarks spanning diverse molecular phenotypes. The model demonstrated high accuracy in predicting variant consequences across multiple modalities, including splicing, gene expression, chromatin accessibility, and transcription factor (TF) binding. Here we examine each modality in turn, highlighting AlphaGenome’s performance and novel methodological features like splice junction modeling and composite scoring.\n\nSplicing Variants: Unified Splice Site, Usage, and Junction Prediction\nOne of AlphaGenome’s most innovative aspects is its treatment of splicing. Previous models like SpliceAI focused on predicting whether a variant disrupts canonical splice sites (donors/acceptors), and others like Pangolin predicted splice site usage (percent spliced in, PSI) changes, but none directly predicted the formation of new splice junctions. AlphaGenome is the first system to jointly predict all three levels of splicing outcomes: (1) the probability of each nucleotide being a splice donor or acceptor, (2) the usage of each splice site (proportion of transcripts using that site), and (3) the presence and read count of specific splice junctions (introns) connecting two sites. By integrating these, AlphaGenome provides a holistic view of how a variant will alter splicing patterns. In practice, this means AlphaGenome can detect subtle splicing changes such as cryptic splice site activation, exon skipping, or novel exon creation, which are often missed by models that only score nearest splice sites.\nPerformance on Splicing Benchmarks: The model’s comprehensive splicing prediction translates into state-of-the-art results on numerous splicing variant benchmarks. AlphaGenome’s authors constructed a unified splicing variant scorer that combines the model’s various splicing outputs into a single composite score for a variant. This involves computing separate sub-scores for splice site disruption, changes in splice site usage (ΔPSI), and any new or lost junctions, then summing them into a composite metric. When evaluated on fine-mapped sQTLs (splicing QTLs) – variants associated with splicing changes in GTEx – AlphaGenome’s composite scorer achieved the highest accuracy in distinguishing true sQTL variants from negatives. It outperformed prior methods in both “nearby SNP” scenarios (variants within 200 bp of a splice site) and more distant variants affecting splicing up to 10 kb away. Similarly, on a task of predicting rare splice-disrupting variants (variants causing aberrant splicing in GTEx outlier samples), AlphaGenome again led both in unsupervised ranking and in a supervised setting.\nNotably, in ClinVar pathogenicity classification for variants affecting splicing, AlphaGenome’s splicing scores beat the previous best method (Pangolin) in every category. For example, for deep intronic or synonymous variants that sometimes create cryptic splice sites, AlphaGenome achieved an auPRC of 0.66 vs 0.64 by Pangolin. In the “splice region” category (variants near exon-intron junctions), it scored 0.57 auPRC vs 0.55 for Pangolin, and even for missense variants (where splicing changes are an off-target effect) it edged out the competition (0.18 vs 0.16). The only benchmark where AlphaGenome did not rank first was a high-throughput splicing reporter assay (MFASS) for which Pangolin slightly exceeded it (auPRC 0.54 vs 0.51). Even there, AlphaGenome still outperformed other tools like SpliceAI and DeltaSplice (each 0.49). Interestingly, the authors found that the splice junction-specific sub-score alone (ignoring site disruption scores) was extremely powerful: it outperformed all prior methods on 5 of 7 benchmarks by itself. This underscores the value of explicit junction prediction – by modeling the creation or loss of specific exon-exon links, AlphaGenome captures effects that purely site-based models might miss. Overall, AlphaGenome was declared a “state-of-the-art splicing VEP model”, achieving SOTA on 6 of 7 tests. The rich splicing output not only improves accuracy but also provides mechanistic insight. For example, AlphaGenome correctly predicted a known case of exon skipping: a 4 bp deletion in the DLG1 gene that causes an exon to be skipped in arterial tissue. The model’s predictions showed reduced usage of the exon’s splice site, disappearance of junctions that include that exon, appearance of a junction skipping over it, and loss of RNA-seq coverage for that exon – precisely matching the experimental observation. In another example, it captured a novel splice junction created by a variant in the COL6A2 gene (Aorta tissue), which led to an extended exon; AlphaGenome’s junction and coverage predictions mirrored the GTEx RNA-seq evidence of that new splicing event. These case studies highlight how AlphaGenome’s fine-grained splicing predictions can pinpoint the exact nature of splicing alterations caused by variants, an ability that was lacking in earlier general models.\n\n\nGene Expression and Regulatory Variants: eQTLs and Enhancer Effects\nFor gene expression phenotypes, AlphaGenome also demonstrated strong performance in predicting variant impacts. It was tested on tasks involving expression quantitative trait loci (eQTLs), which are variants associated with gene expression changes in particular tissues, and on enhancer perturbation experiments, among others.\neQTL Effect Size and Direction: Using fine-mapped GTEx eQTLs as a benchmark, AlphaGenome was compared to previous models (notably Borzoi ensemble and Enformer) for predicting how a variant affects gene expression. The model uses a custom variant scoring approach for eQTLs, where it aggregates predicted changes in relevant expression tracks (like RNA-seq coverage or transcription initiation at a gene’s promoter) into a single score per variant-gene pair. AlphaGenome achieved substantially higher correlation with the actual measured eQTL effect sizes (the “beta coefficients” from statistical fine-mapping) than prior methods. Its average Spearman correlation across tissues was 0.49, versus 0.39 for the previous best (Borzoi). Moreover, as discussed in the Enformer comparison, AlphaGenome greatly improved the sign prediction for eQTLs – an auROC of 0.80 for classifying an allele as up- vs down-regulating, compared to ~0.75 before. These improvements were consistent across most tissues, across both SNPs and indel variants, and even for eQTLs far from the target gene’s transcription start site. The practical effect is that researchers can take AlphaGenome’s score and much more confidently identify not just which variant-gene pairs are likely causal, but also predict whether the variant increases or decreases expression of that gene. In a simulated “GWAS interpretation” exercise, the authors showed that by setting a high threshold on the AlphaGenome eQTL sign score (calibrated to 80% precision), they could assign a reliable direction of effect to at least one candidate variant in 49% of GWAS loci tested – compared to only 11% using a conservative statistical colocalization method. This suggests AlphaGenome can add significant value in post-GWAS analysis by indicating which risk allele is likely gain-of-function vs loss-of-function for nearby genes, thereby generating hypotheses about disease mechanisms.\nEnhancer–Gene Linking: Another gene expression related task is predicting which enhancers regulate which genes (enhancer-gene links). AlphaGenome was evaluated zero-shot on a CRISPR interference (CRISPRi) perturbation dataset from the ENCODE consortium, where enhancers were experimentally silenced and the effect on gene expression was measured. AlphaGenome’s variant scoring for this task would involve simulating the effect of an “enhancer deletion” (perhaps by dropping a sequence segment or altering it) and seeing if the target gene’s predicted expression changes. In identifying true enhancer-gene pairs, AlphaGenome outperformed Borzoi, especially for enhancers located &gt;10 kb from the gene promoter. In other words, it was better at linking distal enhancers to their target genes, presumably because its 1 Mb context and attention mechanism can capture those long-range interactions. Both models still had limitations (they underestimated the effect magnitude of far enhancers, per the authors), but AlphaGenome’s advantage suggests it could be a useful tool for prioritizing likely enhancer target genes, an important aspect of non-coding variant interpretation. Additionally, AlphaGenome was tested on alternative polyadenylation (APA) variant effects (since APA is listed as a modality). While details weren’t given in the excerpt, the model likely predicts usage of polyA sites and was benchmarked on APA QTLs or reporter assays; given the overall success, one can infer it performed strongly there as well (the paper noted SOTA on 24/26 variant tasks, so most likely including APA).\nChromatin Accessibility and TF Binding Variants: AlphaGenome covers chromatin readouts such as open chromatin (DNase-seq, ATAC-seq) and transcription factor ChIP-seq profiles, and these were also included in variant effect tests. For chromatin accessibility, a typical benchmark is to predict the effect of a variant on open chromatin, e.g. in ATAC-seq peaks or DNase sensitivity, often framed as QTL tasks (caQTLs) or allele-specific accessibility. AlphaGenome indeed was evaluated on multiple such datasets – the paper mentions five directionality benchmarks and three causality benchmarks for accessibility variants. In all of them, AlphaGenome outperformed the state-of-the-art single-modality models like ChromBPNet or DeltaSVM. In aggregate, AlphaGenome had an average +8.0% relative improvement in predicting accessibility QTL effect direction compared to ChromBPNet. This means it was better at telling if a variant makes a chromatin site more open or more closed. Similarly, for identifying causal variants among many in linkage (the “causality” task, distinguishing the true causal variant from nearby neutrals in accessibility QTL studies), AlphaGenome matched or slightly exceeded prior best performance (the text noted it was comparable to Borzoi on that, but a supervised model using AlphaGenome’s multi-modal scores boosted performance significantly above Borzoi). The multi-modal nature is key here: the authors showed that using features from multiple modalities of AlphaGenome (e.g. combining its predicted effects on chromatin, expression, and splicing) in a random forest improved causality prediction AUROC from 0.68 to 0.75 – notably higher than using only RNA-seq features or any single source. This demonstrates that AlphaGenome’s ability to simultaneously score a variant’s impact on many layers of gene regulation can be harnessed to better pinpoint causal non-coding variants than looking at one modality alone.\nFor transcription factor binding variants, tasks likely included predicting if a variant disrupts a TF binding motif and thus changes ChIP-seq signal, or high-throughput reporter assays measuring motif activity (like MPRA data for motif variants). While specifics aren’t detailed in the excerpt, AlphaGenome presumably did well: for instance, it outperformed a motif-focused model in at least some TF benchmarks. The model Sei (and a newer one, Orca) had included TF binding predictions, but AlphaGenome with its greater context and resolution likely captured cases where a distal element influences TF binding. We know from the introduction that AlphaGenome outperformed ChromBPNet (a base-resolution accessibility/TF model) on profile predictions by 8–19%, so it stands to reason it would translate to variant effect improvements in those areas as well.\nComposite Variant Scoring: Across these modalities, AlphaGenome often uses composite scores that aggregate its multi-modal predictions into a single variant impact metric for a given task. We saw this in splicing (summing splice site + junction changes) and it’s also applied in other contexts. For example, prior models like Enformer defined a “variant score” by summing predicted changes across relevant tracks (e.g. difference in CAGE signal + difference in DNase signal as a combined regulatory score). AlphaGenome can do the same but with potentially more tracks. The supplementary information notes that when using the exact same composite features as Enformer or Borzoi (like DNase + CAGE, or DNase + histone + RNA), AlphaGenome’s predictions generally outperformed Enformer and Borzoi for all such feature combinations. This implies that even if one uses a simplified scoring scheme mimicking older models, AlphaGenome’s raw predictions are more accurate, leading to better variant prioritization. But one can also exploit its full breadth: the paper’s Fig. 6 (cross-modal variant interpretation) likely shows an example where a variant near the TAL1 gene was simultaneously flagged by AlphaGenome as creating a new TF binding site, increasing accessibility, and boosting gene expression – a combination that explained how a non-coding mutation led to oncogene activation. Such integrated interpretations are a novel strength of AlphaGenome: because it predicts so many modalities at once, one can trace the cascade of effects (e.g., a variant increases chromatin accessibility and H3K27ac at an enhancer, which increases CAGE signal at a promoter, which increases RNA-seq for a gene, etc.). This is extremely useful for understanding complex variant mechanisms and also suggests rich features for integration with other modeling approaches."
  },
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html#cross-modality-integration-and-future-directions-with-genomic-language-models",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html#cross-modality-integration-and-future-directions-with-genomic-language-models",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "Cross-Modality Integration and Future Directions with Genomic Language Models",
    "text": "Cross-Modality Integration and Future Directions with Genomic Language Models\nAlphaGenome provides a powerful platform for predicting molecular phenotypes from DNA sequence. An exciting next step is to consider how its predictions could be integrated with genomic language models – large-scale sequence or gene models like Geneformer, GenSLMs, DNABERT and Evo 2 – to tackle higher-level tasks. While AlphaGenome is a supervised, mechanistic model of genomic function, gene language models are typically trained unsupervised to capture the statistical patterns or “grammar” of sequences or gene networks. Combining these approaches could yield synergistic benefits for tasks such as variant prioritization, phenotype prediction, and genome annotation.\nComplementary Strengths of AlphaGenome and Language Models: A recent perspective highlighted that there are two broad classes of variant effect predictors: activity models like Enformer/AlphaGenome that predict specific molecular activities, and fitness models like genomic language models that infer overall variant deleteriousness from sequence context. These approaches address different angles – AlphaGenome nominates a mechanism and context (e.g., “this variant likely disrupts a liver enhancer of gene X, lowering gene expression”), whereas a genomic LLM (like a GenSLM) might provide an evolutionary or holistic fitness score for the variant based on learned sequence distribution. By combining them, one can get both the “how” and the “how bad” of a variant’s effect. For instance, if AlphaGenome predicts a variant greatly reduces TP53 gene expression, and a genomic language model also assigns that variant a low likelihood (highly deleterious) score, together they make a strong case for prioritization – AlphaGenome explains the regulatory mechanism and the language model concurs that such a change is atypical in evolution and likely harmful. Conversely, an LLM might flag a variant in a gene that is highly dosage-sensitive (something AlphaGenome doesn’t know from sequence alone), helping distinguish which of two expression-changing variants has bigger phenotypic impact. In short, AlphaGenome’s mechanistic predictions and language models’ contextual knowledge could be integrated to improve identification of truly causal and medically relevant variants.\n\nExample Applications\nVariant Prioritization in Clinical Genomics: In genome interpretation (e.g. rare disease diagnostics or non-coding GWAS hits), one could use AlphaGenome to generate a feature set for each variant – predicted changes in splice junctions, gene expression, chromatin states, etc. – and feed these as inputs to a model that also leverages sequence embeddings from a genomic language model (like DNABERT or a GenSLM). A language model like DNABERT encodes local sequence motif context in an unsupervised way, potentially capturing subtle sequence features or evolutionary signals. Combining this with AlphaGenome’s output features could train a powerful classifier to distinguish pathogenic variants from benign. For example, a composite model might take AlphaGenome’s predicted impact on gene Y’s expression and splicing, plus a DNABERT-derived embedding of the variant’s sequence neighborhood (reflecting motif disruptions or conservation learned implicitly), to decide if the variant is likely disease-causing. The language model provides an independent signal of sequence “weirdness” or conservation (e.g., log-likelihood ratio of reference vs alternate allele as in some gLM fitness scores), complementing AlphaGenome’s functional readouts. This could be especially useful for variants where AlphaGenome indicates a moderate effect – the language model might help prioritize those that hit crucial genes or sequences that are ultraconserved.\nPhenotype Prediction and Network Modeling: Gene-focused language models like Geneformer (Theodoris et al., 2023) are trained on large single-cell gene expression datasets to model gene regulatory networks. Geneformer can predict how activating or inhibiting one gene may affect others in a cell’s network (it’s a context-aware transformer that learned gene co-expression and regulatory relationships). AlphaGenome could interface with such models by providing the initial effect of a variant on gene expression, which Geneformer can then propagate through a network. For instance, if AlphaGenome predicts that a non-coding variant decreases the expression of a transcription factor gene in heart tissue, one could input this perturbation into Geneformer to predict downstream changes in cardiac gene networks and phenotypic pathways (since Geneformer has learned which genes tend to respond to which in heart cells). This would enable a more holistic phenotype prediction: AlphaGenome tells us the direct effect of the variant on immediate molecular functions (gene X down-regulated, etc.), and the gene network model predicts the secondary effects (gene X’s targets also change, leading to a pathway dysregulation). Such integration could help answer, for example, “Given this variant’s predicted regulatory effects, what higher-order cellular processes or disease phenotypes might be impacted?” – a step towards bridging genotype to phenotype. In practice, one could imagine a pipeline where AlphaGenome scores all variants in a person’s genome, identifies those that markedly affect important genes or pathways, then a model like Geneformer (or its variants) evaluates which of those could cause the patient’s observed phenotype by simulating gene network perturbations. This cross-talk between sequence-level models and expression-level models could greatly enhance variant prioritization in complex diseases.\nGenome Annotation and Feature Augmentation: Large genomic language models (for DNA) such as GenSLMs and Evo 2 have been trained on entire genomes (e.g., viral or bacterial genomes) to learn sequence representations that encode functional regions and evolutionary constraints. One could use AlphaGenome’s outputs to enrich genome annotations for these models. For example, GenSLM embeddings can classify genomic windows by type (promoter, enhancer, neutral, etc.) to some extent. AlphaGenome’s predictions (like “this 1 Mb region has strong H3K27ac and ATAC peaks here and here, and a CAGE peak at this position”) could be used as additional channels or prompts to a language model to improve its understanding. A hybrid model might feed sequence along with AlphaGenome-predicted track features into a transformer that then performs tasks like enhancer classification or gene–enhancer linking. Essentially, AlphaGenome could act as an automatic annotation layer, providing inputs that guide the language model to focus on biologically relevant signals. This could also work in reverse: a language model could generate hypothetical regulatory sequences (as some generative models do for promoter design), and AlphaGenome could evaluate those designs by predicting if they indeed produce the desired regulatory outputs (high expression of a target gene, etc.). This pairing combines the creative generation ability of gLMs with the evaluatio ability of AlphaGenome in a design loop, for applications like synthetic biology or gene therapy target optimization. In genome annotation projects, one could imagine using an LLM (like GPT-style model) to read AlphaGenome’s predicted patterns and then produce natural-language descriptions – e.g., “AlphaGenome predicts an enhancer in this locus that likely regulates FOXP2 (open chromatin and H3K27ac present, and eQTL signals to FOXP2).” This would greatly aid interpretability, though it requires the language model to be trained or prompted to interpret the numeric outputs.\nIn summary, AlphaGenome’s rich predictive features could serve as high-value inputs or adjuncts to foundation models of the genome. By providing explicit mechanistic signals (which base, which gene, how much effect), AlphaGenome can ground the sometimes abstract embeddings from language models in concrete biology. Conversely, genomic language models can supply broader context – evolutionary, network-level, or literature-driven knowledge – that is outside the scope of AlphaGenome’s training. The combination could enhance tasks like variant prioritization (filtering variants by both functional impact and known gene importance), phenotype prediction (connecting molecular effects to clinical outcomes using learned gene network behavior), and genome annotation (using functional predictions to inform or validate LLM-derived insights). As a recent review noted, activity predictors and genomic LLMs are complementary, and leveraging both may be the key to interpreting variants that induce similar molecular changes but have different organism-level consequences。"
  },
  {
    "objectID": "blog-posts/alphagenome-evolution-genomic-modeling.html#authors-reflections-and-open-issues",
    "href": "blog-posts/alphagenome-evolution-genomic-modeling.html#authors-reflections-and-open-issues",
    "title": "AlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling",
    "section": "Authors’ Reflections and Open Issues",
    "text": "Authors’ Reflections and Open Issues\nThe creators of AlphaGenome are candid about many of these limitations. In the preprint and official blog, they stress that AlphaGenome is a significant step forward but not a solved game. They explicitly list ongoing challenges such as capturing very distant enhancers (&gt;100 kb), improving cell/tissue-specific accuracy, expanding to other species, and bridging the gap from molecular effects to complex traits. They did not attempt personal genome interpretation or clinical diagnosis with AlphaGenome, acknowledging that those remain difficult for AI models and were outside their project’s scope. The team encourages experimental validation of predictions and is actively seeking community feedback on where the model fails. They have also outlined future improvements: plans include incorporating single-cell data for finer cell specificity, extending to additional species, and even integrating developmental or environmental context down the line. This aligns with external critiques that noted the absence of such data in the current model and the importance of including it going forward. Another point of critique has been the accessibility of the model – DeepMind’s choice to release AlphaGenome via API (with code/weights to follow later) drew some community ire given the push for open science. The authors mitigated this by committing to open-source release upon publication, and emphasizing that AlphaGenome is meant to be a foundation others can fine-tune and build on. Nonetheless, until full release, some researchers remain frustrated that an open benchmark against models like Evo 2 or other community models isn’t possible yet.\nIn related evaluations and commentary, experts have lauded AlphaGenome’s achievement (1 Mb context and multi-modal prediction) but also note it as an expected next step rather than a complete solution. There is recognition that “there’s so much biology for which we simply don’t have the data to learn from” even with such models – meaning limitations often arise not just from the model design but from gaps in training data (e.g., unmeasured cell types, conditions, or multi-omic interactions). A critical perspective is that AlphaGenome, like its predecessors, will only be as good as the data available. If certain regulatory logic isn’t present in the training datasets, the model can’t invent it. Thus, one open issue is the need for more and better data (e.g. perturbation experiments to validate causal variant effects, or data from diverse human populations to capture ancestry-specific regulatory variants). The authors of AlphaGenome seem aware of this, as they encourage combining the model’s outputs with other evidence and plan to extend training data in future iterations.\nIn conclusion, AlphaGenome’s potential limitations span multiple dimensions: methodologically, it’s a complex distilled model with finite attention span and black-box internals; in benchmarking, it excels on known tasks but hasn’t proven itself on truly novel or rare-case scenarios; in deployment, it demands heavy compute and careful use (though an efficient API helps); in biological scope, it doesn’t yet cover every species, cell type or polygenic effect; and compared to broad foundation models, it sacrifices universality and generative flexibility for focused accuracy. These shortcomings are actively acknowledged by the authors and the community, and they point towards clear directions for future research. We can expect subsequent versions or related models to address some of these – for example, by integrating single-cell and cross-species data to broaden scope, adopting new attention mechanisms to further extend long-range capture, or leveraging foundation model insights to make AlphaGenome more general. In the meantime, researchers using AlphaGenome should be mindful of its current boundaries: it is a powerful, state-of-the-art tool – but not a magic bullet – and its predictions should be interpreted in context, with an understanding of what might lie outside its view."
  },
  {
    "objectID": "blog-posts/index.html",
    "href": "blog-posts/index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Welcome to my collection of blog posts on genomics, generative modeling, and bioinformatics research.\n\n\n\n\nAugust 19, 2025\nAn in-depth comparison of two cutting-edge diffusion models for genomic sequence generation: DNA-Diffusion and DiscDiff. This analysis explores their architectures, performance metrics, and implications for the future of generative modeling in genomics.\nTopics covered: - Diffusion models in genomics - Architecture comparison of DNA-Diffusion and DiscDiff - Performance evaluation and benchmarks - Applications in genomic research - Future directions in generative genomics\n\n\n\n\nAugust 2, 2025\nA comprehensive exploration of AlphaGenome’s capabilities in regulatory variant prediction and its integration with advanced DNA language models for enhanced genomic modeling. This post synthesizes insights from two key papers on AlphaGenome’s evolution and its applications in genomic prediction.\nTopics covered: - Regulatory variant effect prediction - Integration with advanced DNA language models for enhanced genomic modeling - Multi-scale genomic modeling approaches - Clinical and research applications - Future directions in genomic prediction\n\nMore posts coming soon!"
  },
  {
    "objectID": "blog-posts/index.html#recent-posts",
    "href": "blog-posts/index.html#recent-posts",
    "title": "Blog Posts",
    "section": "",
    "text": "August 19, 2025\nAn in-depth comparison of two cutting-edge diffusion models for genomic sequence generation: DNA-Diffusion and DiscDiff. This analysis explores their architectures, performance metrics, and implications for the future of generative modeling in genomics.\nTopics covered: - Diffusion models in genomics - Architecture comparison of DNA-Diffusion and DiscDiff - Performance evaluation and benchmarks - Applications in genomic research - Future directions in generative genomics\n\n\n\n\nAugust 2, 2025\nA comprehensive exploration of AlphaGenome’s capabilities in regulatory variant prediction and its integration with advanced DNA language models for enhanced genomic modeling. This post synthesizes insights from two key papers on AlphaGenome’s evolution and its applications in genomic prediction.\nTopics covered: - Regulatory variant effect prediction - Integration with advanced DNA language models for enhanced genomic modeling - Multi-scale genomic modeling approaches - Clinical and research applications - Future directions in genomic prediction\n\nMore posts coming soon!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adrian’s Generative Genomics Blog",
    "section": "",
    "text": "This blog explores the intersection of genomics, generative modeling, and bioinformatics. Here you’ll find insights into cutting-edge research, computational methods, and their applications in understanding the genome.\n\n\n\nDiffusion Models in Genomics: DNA-Diffusion and DiscDiff - An in-depth comparison of two cutting-edge diffusion models for genomic sequence generation, exploring their architectures, performance metrics, and implications for the future of generative modeling in genomics.\nAlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling - A comprehensive exploration of AlphaGenome’s capabilities in regulatory variant prediction and its integration with advanced DNA language models for enhanced genomic modeling.\n\n\n\n\nThis blog serves as a platform for sharing insights from recent research papers, particularly focusing on computational genomics and language model applications in biology. Each post aims to provide both technical depth and accessible explanations of complex genomic concepts.\n\nBuilt with Quarto"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Adrian’s Generative Genomics Blog",
    "section": "",
    "text": "Diffusion Models in Genomics: DNA-Diffusion and DiscDiff - An in-depth comparison of two cutting-edge diffusion models for genomic sequence generation, exploring their architectures, performance metrics, and implications for the future of generative modeling in genomics.\nAlphaGenome Evolution: Advancing Regulatory Variant Prediction and Genomic Modeling - A comprehensive exploration of AlphaGenome’s capabilities in regulatory variant prediction and its integration with advanced DNA language models for enhanced genomic modeling."
  },
  {
    "objectID": "index.html#about-this-blog",
    "href": "index.html#about-this-blog",
    "title": "Adrian’s Generative Genomics Blog",
    "section": "",
    "text": "This blog serves as a platform for sharing insights from recent research papers, particularly focusing on computational genomics and language model applications in biology. Each post aims to provide both technical depth and accessible explanations of complex genomic concepts.\n\nBuilt with Quarto"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my genomics blog! I’m passionate about exploring the intersection of computational biology, machine learning, and genomics research.\n\n\nThis blog covers several key areas in modern genomics:\n\nComputational Genomics: Analysis and interpretation of genomic data using computational methods\nMachine Learning in Biology: Applications of ML and AI in genomic prediction and modeling\nRegulatory Genomics: Understanding how regulatory elements control gene expression\nEvolutionary Genomics: Studying genomic evolution and its implications\nClinical Genomics: Translating genomic insights into clinical applications\n\n\n\n\nPosts are organized in the blog-posts/ directory, with each post focusing on synthesizing insights from recent research papers. The goal is to provide both technical depth and accessible explanations of complex genomic concepts.\n\n\n\nFor questions or suggestions about the blog content, feel free to reach out through the repository.\n\nThis blog is built using Quarto, a modern scientific and technical publishing system."
  },
  {
    "objectID": "about.html#focus-areas",
    "href": "about.html#focus-areas",
    "title": "About",
    "section": "",
    "text": "This blog covers several key areas in modern genomics:\n\nComputational Genomics: Analysis and interpretation of genomic data using computational methods\nMachine Learning in Biology: Applications of ML and AI in genomic prediction and modeling\nRegulatory Genomics: Understanding how regulatory elements control gene expression\nEvolutionary Genomics: Studying genomic evolution and its implications\nClinical Genomics: Translating genomic insights into clinical applications"
  },
  {
    "objectID": "about.html#blog-structure",
    "href": "about.html#blog-structure",
    "title": "About",
    "section": "",
    "text": "Posts are organized in the blog-posts/ directory, with each post focusing on synthesizing insights from recent research papers. The goal is to provide both technical depth and accessible explanations of complex genomic concepts."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "",
    "text": "For questions or suggestions about the blog content, feel free to reach out through the repository.\n\nThis blog is built using Quarto, a modern scientific and technical publishing system."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "",
    "text": "Generative AI models are increasingly being applied to genomic sequences for tasks like designing synthetic DNA with desired regulatory functions. Two recent approaches – DNA-Diffusion and DiscDiff – explore diffusion models for DNA sequence generation from different angles. DNA-Diffusion (2024) leverages a diffusion model to generate synthetic regulatory DNA elements (short sequences ~200 bp) conditioned on cell type, aiming to control chromatin accessibility and gene expression. DiscDiff (2024) introduces a framework for DNA sequence generation across species using a latent diffusion model, coupled with a post-processing algorithm, to produce realistic DNA sequences (including regulatory regions and gene sequences) with high fidelity. Both models set new milestones in DNA generative modeling: DNA-Diffusion demonstrates the ability to create cell type-specific enhancers in silico, while DiscDiff achieves state-of-the-art performance in generating both short and long DNA sequences across multiple species. Despite sharing the diffusion paradigm, they differ in methodology and objectives – DNA-Diffusion focuses on conditional generation of regulatory sequences for synthetic biology, whereas DiscDiff proposes a latent discrete diffusion approach to broadly model genomic sequences. Below, we discuss each model’s achievements and methods, compare their similarities and differences (including how DiscDiff tackles a key concern in DNA-Diffusion’s design), and examine why diffusion models were chosen over traditional sequence models. We also highlight the data used, connections to prior DNA language models, and the limitations and potential applications of these generative genomics models in the context of AI for virtual cells and beyond."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#introduction",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#introduction",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "",
    "text": "Generative AI models are increasingly being applied to genomic sequences for tasks like designing synthetic DNA with desired regulatory functions. Two recent approaches – DNA-Diffusion and DiscDiff – explore diffusion models for DNA sequence generation from different angles. DNA-Diffusion (2024) leverages a diffusion model to generate synthetic regulatory DNA elements (short sequences ~200 bp) conditioned on cell type, aiming to control chromatin accessibility and gene expression. DiscDiff (2024) introduces a framework for DNA sequence generation across species using a latent diffusion model, coupled with a post-processing algorithm, to produce realistic DNA sequences (including regulatory regions and gene sequences) with high fidelity. Both models set new milestones in DNA generative modeling: DNA-Diffusion demonstrates the ability to create cell type-specific enhancers in silico, while DiscDiff achieves state-of-the-art performance in generating both short and long DNA sequences across multiple species. Despite sharing the diffusion paradigm, they differ in methodology and objectives – DNA-Diffusion focuses on conditional generation of regulatory sequences for synthetic biology, whereas DiscDiff proposes a latent discrete diffusion approach to broadly model genomic sequences. Below, we discuss each model’s achievements and methods, compare their similarities and differences (including how DiscDiff tackles a key concern in DNA-Diffusion’s design), and examine why diffusion models were chosen over traditional sequence models. We also highlight the data used, connections to prior DNA language models, and the limitations and potential applications of these generative genomics models in the context of AI for virtual cells and beyond."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#dna-diffusion-diffusion-for-cell-type-specific-regulatory-dna-design",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#dna-diffusion-diffusion-for-cell-type-specific-regulatory-dna-design",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "DNA-Diffusion: Diffusion for Cell Type-Specific Regulatory DNA Design",
    "text": "DNA-Diffusion: Diffusion for Cell Type-Specific Regulatory DNA Design\nDNA-Diffusion (Ferreira DaSilva et al. 2024) is a conditional diffusion model developed to design synthetic DNA regulatory elements (enhancers) that can drive gene expression in a cell type-specific manner. The model’s goal is to aid synthetic biology and gene therapy by generating 200 bp DNA sequences with desired regulatory activity – for example, creating an enhancer sequence that is active (open chromatin and transcriptionally potent) in one cell type but not in others. To achieve this, DNA-Diffusion uses the standard diffusion model framework adapted to one-dimensional DNA sequences:\n\nArchitecture & Method: DNA-Diffusion employs a U-Net convolutional network (inspired by image diffusion models) that iteratively denoises a noisy sequence input. Each DNA sequence is represented as a one-hot encoded matrix (4 channels for A/C/G/T by 200 bp length). During the forward diffusion process, Gaussian noise is added to these one-hot sequence vectors over multiple timesteps until the sequence becomes nearly random noise. Training involves learning the reverse diffusion – the U-Net is given a noisy sequence plus a time-step embedding and a cell type condition label, and it learns to predict and remove the noise to recover the original sequence at that timestep. Essentially, the model is conditioned on cell type so that it will generate sequences with features specific to that cell type’s open chromatin profiles. After training, new sequences can be generated by starting from random noise and iteratively denoising it 50 steps down to a synthetic DNA sequence that “reflects the characteristics of the target cell type”. The diffusion model “receives three inputs: DNA sequences, a timestep, and cell type labels” and uses the cell-type embedding to guide the sequence generation toward the desired regulatory profile\nKey Achievement: DNA-Diffusion showed that diffusion models can “robustly generate DNA sequences with cell type-specific regulatory potential.” In evaluations, the authors verified that the synthetic sequences retained hallmark properties of real (endogenous) regulatory DNA. For instance, generated sequences had realistic combinations of transcription factor binding sites and were predicted (by external models) to produce the intended chromatin accessibility and gene expression patterns in the target cell types. In fact, using state-of-the-art predictive models (like Enformer/AlphaGenome-style epigenomic predictors), they found that DNA-Diffusion sequences could activate genes and open chromatin in silico similarly to or even beyond real enhancers for those cell contexts. This demonstrates the potential of the model to modulate gene expression via designed DNA, paving the way for applications in mammalian synthetic biology and precision gene therapy.\nData Used (Endogenous vs Synthetic): DNA-Diffusion was trained on real genomic sequences – specifically, DNase hypersensitive sites (DHS) of length ~200 bp from a few well-studied human cell lines (GM12878 lymphoblastoid cells, K562 erythroleukemia cells, and HepG2 liver cells). These “endogenous” sequences are actual regulatory DNA elements native to the human genome that were accessible (open chromatin) in specific cell types, drawn from a DHS index dataset (ENCODE/Roadmap epigenomics data) curated by Meuleman et al.. In the context of the paper, “endogenous” data refers to real biological sequences present in the genome, as opposed to synthetic sequences generated by the model. The authors ensured that the diffusion model’s outputs were biologically plausible by comparing them to such endogenous sequences. Notably, they checked that the synthetic enhancers did not trivially copy training examples – out of hundreds of thousands of generated sequences, only a handful were exact matches to known DHS sequences (e.g. ~50 overlaps for GM12878, indicating high novelty/diversity). This indicates the model was creating novel sequence variants rather than memorizing, a critical property for generative design.\nAddressing Diffusion on Discrete Data: One methodological detail is that DNA-Diffusion applied Gaussian noise to one-hot vectors – meaning during noising, a DNA sequence (which initially has binary 0/1 values in each nucleotide channel) becomes a continuous valued matrix. This is a straightforward adaptation of image/text diffusion to DNA, but it introduces intermediate states that are not valid DNA sequences (e.g. partial activation of multiple nucleotide channels). The model must learn to navigate these continuous states and ultimately produce a valid discrete sequence (usually by taking the argmax base at each position after the final denoising step). The authors used a fixed noise schedule (50 diffusion steps) and trained the U-Net to predict the added noise at each step so that it can subtract it out. While effective, using standard normal noise on one-hot encodings can cause a kind of “rounding” problem: the model’s output before discretization might be ambiguous or unrealistic (like 0.5 A + 0.5 C at one position). DNA-Diffusion dealt with this by relying on the neural network to produce sharp outputs that can be thresholded into A/C/G/T. However, this approach left a space for improvement – as we will see, DiscDiff explicitly tackles the challenge of discrete sequence diffusion by altering how the diffusion is performed (hint: via a latent space encoding).\n\nIn summary, DNA-Diffusion’s methodology demonstrated how diffusion models can be adapted to DNA sequence generation with conditioning. It achieved the generation of functional, cell-specific DNA sequences and established a baseline for controlling gene regulatory elements via generative models. One primary concern with this approach is the continuous noising of discrete data, which can introduce inaccuracies. The DiscDiff paper addresses this concern through an alternative diffusion strategy."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#discdiff-latent-diffusion-model-for-dna-sequence-generation",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#discdiff-latent-diffusion-model-for-dna-sequence-generation",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "DiscDiff: Latent Diffusion Model for DNA Sequence Generation",
    "text": "DiscDiff: Latent Diffusion Model for DNA Sequence Generation\nDiscDiff (Li et al. 2024) presents a novel two-part framework for DNA generation, consisting of (1) DiscDiff, a latent diffusion model (LDM) tailored to discrete sequences, and (2) Absorb-Escape, a post-processing algorithm to refine generated sequences. The motivation behind DiscDiff is to overcome the unique challenges of applying diffusion models to DNA, particularly the discrete nature of nucleotide sequences and the need for diverse, high-fidelity outputs across different sequence types (regulatory regions and protein-coding sequences, potentially in multiple species). DiscDiff’s approach can be seen as a more general-purpose DNA generator: it is trained on a large multi-species DNA dataset and can generate both short sequences (like promoters/enhancers) and longer sequences (gene regions up to 2 kb). Importantly, DiscDiff directly addresses the “continuous vs discrete” mismatch present in models like DNA-Diffusion by introducing a latent representation for sequences and a correction mechanism for any errors in conversion between latent and actual DNA.\n\nLatent Diffusion Methodology: Rather than diffusing on one-hot DNA directly, DiscDiff first encodes DNA sequences into a continuous latent space using a specialized autoencoder (in fact, they experiment with architectures including CNNs and transformers – e.g. a Swin-transformer – for the encoder/decoder, even noting that incorporating components like those in Enformer improved performance in one variant). The encoder compresses a DNA sequence into a latent vector (of lower dimension), and the decoder can reconstruct the sequence from this latent (this is akin to a VAE, but they focus on minimizing reconstruction error). Once this DNA-to-latent mapping is established, a diffusion model is trained in the latent space: Gaussian noise is added to the latent vectors rather than to the raw sequence, and a diffusion U-Net (or similar) learns to denoise in latent space. Because the latent space is continuous by construction, the diffusion process here is naturally handled with continuous noise, avoiding the problem of generating physically impossible intermediate DNA states. After training, DiscDiff generates new sequences by sampling a random latent vector, iteratively denoising it via the diffusion model, and then passing the final denoised latent through the decoder to produce a DNA sequence.\nAbsorb-Escape (Refinement Step): A critical innovation in DiscDiff is the Absorb-Escape algorithm, which aims to fix any “rounding errors” or local inconsistencies that arise when converting the denoised latent back into a discrete sequence. Even with a good autoencoder, the decoded sequence might have minor errors (e.g. low-probability nucleotides where there should be a clear choice). Absorb-Escape addresses this by leveraging an autoregressive model in a post-hoc manner. Specifically, they use Hyena, a state-of-the-art autoregressive sequence model, to scan through the generated sequence and correct mistakes. The Absorb-Escape algorithm works by “absorbing” the reliable parts of the sequence and “escaping” (redoing) the uncertain parts, effectively combining the strengths of diffusion (global realism and diversity) with the strengths of autoregressive models (local coherence and grammar). This hybrid approach was shown to significantly improve the quality of generated sequences – for example, Absorb-Escape improved DiscDiff’s performance by ~4% on long sequences and enhanced the model’s ability to precisely match known motif patterns. In essence, DiscDiff generates a draft sequence in one shot via latent diffusion, and then Absorb-Escape fine-tunes that sequence to eliminate small errors, much like an editor refining a rough draft.\nAchievements and Evaluation: DiscDiff is reported to outperform prior generative models for DNA in both short sequence generation (enhancers, promoters) and long sequence generation (gene regions). It was evaluated on a suite of metrics, including a latent Frechet distance (S-FID) measuring how close the distribution of generated sequences is to real sequences in a learned feature space, and motif distribution correlation, which checks if the frequency of biological motifs (like transcription factor binding sequences) in generated DNA matches those in real DNA. DiscDiff had the smallest latent distance and highest motif correlation compared to other baseline models (including earlier diffusion models and an autoregressive transformer), indicating its samples are both realistic and capture the underlying genomic patterns very well. Notably, the authors compared DiscDiff to a discrete diffusion model (DDSM) and to a transformer-based generative model, and DiscDiff achieved the best trade-off of accuracy and diversity. They also performed a head-to-head comparison with an autoregressive DNA language model (Hyena) on conditional generation tasks; each had strengths for certain motif types, but combining them via Absorb-Escape yielded the most realistic sequences overall。\nData Used: A major contribution of DiscDiff is the introduction of EPD-GenDNA, a comprehensive multi-species dataset of DNA sequences for generative modeling. EPD-GenDNA is built from the Eukaryotic Promoter Database and contains 160,000 unique sequences from 15 species, including both regulatory regions (promoters/enhancers) and protein-coding segments. Sequence lengths in the dataset are either 256 bp (promoter-centered windows) or 2048 bp (extended genomic regions around transcription start sites). Each sequence comes with rich annotations like species and cell type of origin and gene expression info. This dataset allowed DiscDiff to be the first DNA diffusion model tested across multiple species (prior works were largely single-species and much smaller). By training on this diverse data, DiscDiff learned to generate DNA that is not just human-like but captures broader genomic “languages.” The diversity of training data is reflected in its outputs: DiscDiff can sample novel DNA sequences that maintain natural diversity (measured by unique n-gram content close to real data). In fact, the authors emphasize that diversity is a key metric for genome sequence generation, to avoid mode collapse and to ensure synthetic sequences explore the full space of possibilities. DiscDiff’s diffusion approach, combined with latent compression, was explicitly designed to promote diversity while still matching biological distributions.\nKey Differences from DNA-Diffusion: DiscDiff directly tackled the main concern one might have with a method like DNA-Diffusion: the use of standard Gaussian noise on discrete sequences. In DNA-Diffusion, adding continuous noise to one-hot DNA could lead to off-manifold intermediate states that the model must correct. DiscDiff avoids diffusing on raw sequences; instead, it performs diffusion in a learned continuous latent space where noise application is natural. The consequence is fewer downstream errors when decoding sequences. And if errors do occur, the Absorb-Escape step fixes them, resulting in highly realistic final sequences. In summary, DiscDiff’s methodology is more complex (involving an encoder, a diffusion model, and an AR refiner), but this complexity is justified by significantly improved quality and the ability to handle long sequences. DiscDiff also operates largely unconditionally or with broad conditioning (it can generate sequences without needing a specific cell type label, or potentially conditioned on species or desired motifs), whereas DNA-Diffusion was a fully conditional model (cell type-specific). Despite these differences, both models share the core idea that diffusion models can generate diverse, high-fidelity DNA – they just implement it in different ways to accommodate the discrete sequence data."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#why-diffusion-models-diffusion-vs.-autoregressive-transformers",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#why-diffusion-models-diffusion-vs.-autoregressive-transformers",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "Why Diffusion Models? (Diffusion vs. Autoregressive Transformers)",
    "text": "Why Diffusion Models? (Diffusion vs. Autoregressive Transformers)\nA central question is why these works chose diffusion models for DNA generation instead of more traditional autoregressive (AR) sequence models like Transformers or RNN-based language models. Several reasons emerge from the papers:\n\nAvoiding Mode Collapse & Enhancing Diversity\nEarlier attempts at DNA generation used Generative Adversarial Networks (GANs) or even direct CNN-based generators, but those often suffered from mode collapse and limited diversity – i.e. they tended to produce very similar or repetitive sequences, failing to cover the full variability of genomic patterns. Autoregressive language models can also become over-confident and repetitive, essentially learning to generate the most frequent patterns and ignoring rarer variants. In genomic sequence generation, such loss of diversity is “detrimental” because capturing the wide range of possible sequences (especially for non-coding DNA where many different motifs and combinations exist) is crucial. Diffusion models naturally encourage diversity by their stochastic sampling process – each diffusion run can produce a different outcome, and there’s no easy way for the model to collapse to a single mode since it has to learn to reconstruct data from random noise. Dhariwal & Nichol (2021) observed that diffusion models can outperform GANs in sample diversity. In the context of DNA, DiscDiff explicitly highlights that autoregressive transformers “generate samples with lower diversity than diffusion models” and tend to repeat themselves, whereas diffusion models produce a richer variety of outputs. This is a major motivation: to generate truly novel DNA sequences (for synthetic biology or data augmentation), one needs the generative model to explore many modes of the sequence distribution, which diffusion is well-suited for.\n\n\nIterative Refinement and Global Coherence\nDiffusion models generate data by iterative denoising, which allows them to make large-scale decisions in a sequence in a coarse-to-fine manner. This can help with global coherence of the sequence in a way that one-base-at-a-time generation sometimes struggles with. An AR model decides each next nucleotide based only on previous ones; if it makes a bad choice early, it can derail the rest of the sequence (accumulating errors). This can lead to issues like local repetitions or inconsistent long-range structure in AR outputs. Diffusion, in contrast, starts with a holistic (if noisy) view and refines everything together, potentially balancing local and global features as it denoises. In DNA-Diffusion’s case, the U-Net has access to the entire sequence and the cell type context at once, so it can, for example, ensure that if a certain transcription factor motif is needed at the start and another at the end, it can place both during the denoising process. This iterative global refinement tends to produce sequences that capture higher-order dependencies (like spacing between motifs, or overall GC-content) more naturally. That said, diffusion models sometimes under-perform in local syntax (e.g. occasional minor errors in a sequence) compared to AR models, which is why DiscDiff introduced Absorb-Escape to inject local autoregressive strength into the final output.\n\n\nHandling Long Contexts\nGenomic sequences can be very long (thousands to millions of bases). Autoregressive transformers face computational challenges with long contexts due to quadratic attention scaling and memory limits. Notably, the Evo 2 language model (discussed below) addresses this with 1 million token context, but it requires enormous model sizes (billions of parameters) and specialized training regimes. Diffusion models, especially in latent space, offer an alternative: compress the sequence and then generate. DiscDiff’s latent diffusion is an example – by encoding 2048bp sequences into a latent, they sidestep dealing with thousands of tokens in the generative model directly. This makes the generation of long sequences more tractable on modest computational budgets. In effect, diffusion models can leverage latent representations and iterative sampling to cover long-range genomic structure without needing an exorbitantly large model at generation time. This is partly why DiscDiff could demonstrate multi-kilobase sequence generation with high fidelity.\n\n\nConditional Generation is Straightforward\nBoth DNA-Diffusion and DiscDiff needed to condition on certain information (cell type for DNA-Diffusion; in DiscDiff’s case, they considered conditional generation in experiments, such as giving the model a motif to include or a species label). In diffusion models, conditioning can often be done by concatenating the condition to the input or modifying the denoising network (e.g. through cross-attention or FiLM layers) without fundamentally changing the generation process. DNA-Diffusion simply concatenated a one-hot cell type vector as additional input channels to the U-Net and as a global label, which is a natural extension of image diffusion techniques. In contrast, conditioning an autoregressive DNA model on metadata might require special tokens or complex prompt design, and ensuring the model actually respects the condition can be tricky. The diffusion approach thus provided a clean way to inject context like “generate an enhancer for K562 cells” into the process. Additionally, diffusion models can integrate multiple conditions (if needed) by altering the denoising score function, offering flexibility for future extensions (e.g. generate a sequence with both a certain GC content and a specific histone mark profile – one could condition the diffusion model on both).\n\n\nDiscrete Data Challenges and Solutions\nA noteworthy point is that vanilla diffusion was designed for continuous data (like pixel intensities). Applying it to DNA (discrete alphabet) is non-trivial, and yet both papers show viable solutions. DNA-Diffusion took the simpler route of using continuous noise on one-hot vectors, effectively pretending DNA is like an image and relying on the network to snap it back to one-hot. This works but could introduce errors – imagine the model outputs a 0.8 for “A” and 0.7 for “C” at one position, which base do you choose? It requires a hard decision that could slightly perturb the sequence’s validity (this could potentially create an out-of-distribution sequence if not careful). DiscDiff’s latent approach is a more principled solution: by learning a continuous embedding of DNA, the diffusion model always operates in a continuous space that (ideally) corresponds to valid sequences when decoded. The problem of “rounding” (continuous outputs not mapping cleanly to discrete tokens) is alleviated by design and explicitly corrected with Absorb-Escape. Moreover, other research has explored discrete diffusion (e.g. D3PM or BitDiffusion for sequences, and DDSM using a Dirichlet distribution for DNA). These confirm that special noise distributions can be used for discrete data, but they tend to be more complex or less efficient. DiscDiff’s contribution was showing that Latent Diffusion Models (LDMs) – which were very successful in imaging – can be adapted to DNA with new encoder/decoder architectures and a bit of autoregressive help. This substantially reduces the computational cost compared to operating in the original sequence space (DDSM and related discrete DMs were found to be computationally intensive), making diffusion a practical choice for genomics.\nIn short, diffusion models were chosen because they offer greater sample diversity, robust global generation and flexible conditioning, which are valuable for de novo DNA design. The tradeoff is dealing with discrete data issues, but as DiscDiff demonstrated, this can be overcome with a creative combination of techniques. The result is generative models that can imagine a wide variety of realistic DNA sequences – something that a naïve transformer might struggle with, either collapsing to repetitive motifs or requiring an extremely large model to capture all variations. It’s worth noting that the DiscDiff authors still acknowledge the strengths of autoregressive models, which is why they integrated Hyena to handle fine details. Thus, the emerging view is that diffusion and autoregressive approaches can be complementary for biological sequence generation. Some recent works even try to combine them (e.g. using a language model to guide diffusion), and DiscDiff’s Absorb-Escape is a novel instance of such a combination."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#comparison-with-prior-and-related-models",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#comparison-with-prior-and-related-models",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "Comparison with Prior and Related Models",
    "text": "Comparison with Prior and Related Models\nBoth DNA-Diffusion and DiscDiff build upon and differ from previous approaches to modeling DNA sequences:\n\nVersus Autoregressive “DNA Language Models”: Prior to diffusion models, many works applied language-model style architectures to DNA. For example, recurrent networks or Transformers have been used to learn genome sequences and even generate them or score them (e.g. Genomic GPTs, DNABERT for classification, or generative LSTMs for DNA). As DiscDiff’s related work notes, large autoregressive models (including Transformers and state-space models) have indeed been trained on genomic sequences. They can capture sequence dependencies and have seen success in tasks like predicting functional genomic signals or generating DNA one base at a time. Evo 2 is a very recent example of a high-profile AR model: Evo 2 (Brixi et al. 2025) is described as a “biological foundation model” trained on an unprecedented 9.3 trillion DNA bases across all domains of life. Evo 2 is designed to both predict functional effects of genetic variation and generate genomic sequences, covering bacteria, archaea, and eukaryotes in one model. In concept, Evo 2 and DiscDiff share a grand vision: modeling genomes across all life for design and prediction. We can envision using these models in tandem or comparing insights. For example, DiscDiff could generate candidate promoter sequences and Evo 2 (or another foundation model) could evaluate their likelihood or functional scores (since Evo 2 can predict epigenomic signals, similar to AlphaGenome described below). Conversely, one could use Evo 2 to suggest a rough sequence design and then use DiscDiff’s refinement (via diffusion + Absorb-Escape) to polish certain regions. Both represent steps toward AI-driven genome design. It’s notable that Evo 2’s authors explicitly mention enabling “genomic and epigenomic design” as a goal– a goal very much in line with what DNA-Diffusion and DiscDiff are doing on a smaller scale. In summary, DiscDiff and Evo 2 share the vision but differ in strategy: DiscDiff demonstrates that with the right model design, even relatively small datasets can yield powerful generative DNA models, whereas Evo 2 demonstrates the power of scale and breadth, treating genome modeling as a language modeling problem at internet-scale data.\nVersus Other Diffusion Models (and prior generative work): DiscDiff wasn’t the first attempt to adapt diffusion to biological sequences. The authors cite DDSM (Avdeyev et al. 2023), a Dirichlet Diffusion Score Model for human DNA. DDSM used a Dirichlet noise distribution to diffuse probability vectors over the DNA alphabet, thereby maintaining a valid distribution at each step (no need for Gaussian with one-hots). It achieved good results especially on conditional tasks, but DDSM still operated in the original sequence length (1024 bp human sequences) and was computationally heavy. DiscDiff differentiates itself by using latent compression (which DDSM did not) and by demonstrating use across species and both coding/regulatory regions. Additionally, EvoDiff (Alamdari et al. 2023) is mentioned – EvoDiff was a diffusion model for protein sequences (amino acid sequences) which also had to handle discrete tokens. EvoDiff and related models (like ProteinMPNN or Score-based generative models for proteins) illustrate that diffusion can explore sequence space in biology broadly. DiscDiff takes inspiration from these but tailors the approach to DNA. It introduces domain-specific solutions like Absorb-Escape, which were not present in EvoDiff. In terms of performance, DiscDiff reported superior results to previous diffusion models in DNA (including DDSM and a BitDiffusion adaptation). It also compared against D3PM (a discrete diffusion framework from Austin et al. 2021) and found DiscDiff’s outputs had closer motif statistics to the ground truth.\nVersus GANs and heuristic sequence design: Before diffusion models, GANs were tried for DNA – e.g. EnhancerGAN, FeedbackGAN for enhancer or promoter generation. These had some success but often produced sequences that, upon evaluation, lacked the full diversity of real data or contained artifacts. For instance, one might get a few strong motifs repeated too often (mode collapse) or sequences that did not integrate multiple regulatory signals well. Both DNA-Diffusion and DiscDiff make the case that diffusion models overcome these issues, producing more varied and realistic sequences. The quantitative metrics in DiscDiff (like diversity and S-FID) back this claim, as DiscDiff’s diversity was very close to the real dataset whereas GAN baselines were presumably worse (the paper notes GAN outputs were less diverse and had mode collapse issues). Another advantage is training stability: GANs are notoriously fickle to train, whereas diffusion model training is a straightforward maximum likelihood training (denoising score matching) which is generally stable albeit slow. This reliability is important if we want a method that can scale or be used as a basis in many labs."
  },
  {
    "objectID": "blog-posts/dna-diffusion-genomic-sequences.html#limitations-and-applications-so-what-of-generative-genomics",
    "href": "blog-posts/dna-diffusion-genomic-sequences.html#limitations-and-applications-so-what-of-generative-genomics",
    "title": "Comparative Analysis: DNA-Diffusion and DiscDiff in Genomic Sequence Generation",
    "section": "Limitations and Applications – “So What” of Generative Genomics?",
    "text": "Limitations and Applications – “So What” of Generative Genomics?\nWhile these diffusion models for DNA are technically impressive, one might ask: what are the practical applications of generating DNA sequences, and what limitations remain? The papers provide some hints, and we can extrapolate possible uses in research and biotechnology:\n\nSynthetic Biology & Gene Therapy Design\nA primary motivation for DNA-Diffusion was to enable precise control of gene expression through synthetic DNA. In practice, this could mean designing an enhancer or promoter for a therapeutic gene – for example, creating a regulatory sequence that only turns on a gene in T-cells but not in other cells, or an enhancer that is active only in low-oxygen conditions, etc. Previously, one would have to screen many candidate sequences or rely on minimal motif tweaking. DNA-Diffusion provides a way to algorithmically design such sequences by specifying the desired context (cell type) and letting the model generate candidates. This is useful for building gene therapies that need cell-specific targeting or for engineering cell-based therapies where you want a gene to be tightly controlled. Another application is in biomanufacturing: designing promoters that maximize production of a protein in a cell line (the model could be conditioned on a context representing high expression, for instance). DiscDiff’s authors explicitly mention “potential implications for gene therapy and protein production”– imagining that their model (which can generate entire promoters or even genes) could be used to create novel gene constructs optimized for these purposes. For protein production, one might use DiscDiff to generate coding sequences (synonymous variants of a gene) that have favorable codon usage or mRNA structure for high translation efficiency. Because DiscDiff saw many coding regions, it could conceivably generate a gene sequence that is different from any natural gene but still yields a functional protein, perhaps optimized for expression in a certain organism.\n\n\nData Augmentation and Privacy\nIn human genomics research, a big challenge is data sharing and scarcity of labeled examples (and privacy concerns with real genomes). Generative models can create synthetic genomic data that mimics real data distribution without containing exact private information. For instance, the Kenneweg et al. (2024) work (arXiv 2412.03278, referenced in DiscDiff context) used diffusion to generate entire synthetic human genotypes for exactly this purpose – enabling researchers to train models on synthetic genomes when real ones are protected. While DiscDiff itself didn’t explicitly demonstrate genome-scale generation, its approach to modeling long sequences and multi-species data is a step in that direction. One can imagine using DiscDiff or similar to generate synthetic patient genomes that preserve allele frequency spectra and linkage disequilibrium patterns, which would be extremely valuable for genomic studies while respecting privacy. Even at the smaller scale, synthetic enhancers from DNA-Diffusion could augment datasets for training predictive models: e.g., to train a classifier to identify cell-type-specific enhancers, one could add some model-generated examples to balance classes or explore feature space. Both papers noted that augmenting real data with synthetic data improved performance of downstream models. Thus, generative DNA models can serve as “data generators” to bolster learning tasks in genomics.\n\n\nUnderstanding Regulatory Grammar\nGenerative models can be tools for science discovery. By analyzing what the model generates, researchers can infer what patterns it “thinks” are necessary for function. DNA-Diffusion, for example, could be queried to produce multiple enhancers for the same cell type and then one could look for common motifs – if the model consistently inserts a particular motif, it reinforces the evidence that motif is important for that cell type. Conversely, one could ask the model to generate a sequence with certain constraints (if the model supports that) to test hypotheses (e.g., “generate a K562 enhancer sequence that does not contain GATA1 motif” – if the model struggles, that suggests GATA1 is essential for K562 enhancers). DiscDiff’s Absorb-Escape uses an AR model that could potentially assign probabilities to sections of sequence; low confidence regions might correspond to biologically constrained positions (like the TATA box which must be a specific sequence). In this way, generative models can help identify key sequence features and perhaps design experiments. The DNA-Diffusion study itself went a step further: they took synthetic sequences and experimentally tested them in silico by inserting them into genomic contexts and using predictive models to see if they activate genes. They even identified cases where synthetic sequences activated genes more strongly than natural ones, suggesting we could design “super-enhancers” or novel regulatory switches that nature hasn’t utilized. This opens a creative side to genomics – using AI to invent new biological components.\n\n\nLimitations and Future Directions\n\nFuncational Validity: Despite promising in silico results, a clear limitation is that experimental validation is needed. For DNA-Diffusion’s sequences, the real test is to synthesize them and put them in cells to see if they indeed produce the chromatin and expression changes predicted. Models like Enformer (and AlphaGenome) are powerful predictors, but they are not perfect; a sequence predicted to be a strong enhancer might not work in vivo due to chromatin context or 3D genome interactions not accounted for. Thus, one limitation is that generative models may produce sequences that look good to current predictive models (which are trained on known biology), but biology could still surprise us with unintended effects (e.g. the sequence might form a secondary structure or be toxic in some way). DiscDiff’s sequences similarly have not been experimentally tested – they are evaluated by statistical metrics. So a limitation is we don’t yet know if DiscDiff can generate, say, a functional gene that expresses properly, or a promoter that actually drives transcription in a living cell. It’s one thing to match k-mer distributions; it’s another to have all subtle features needed for function. Future work likely will involve moving these models “from silico to vivo,” testing a sample of generated sequences in wet-lab assays (e.g., massively parallel reporter assays for enhancers) to validate their functionality. Until then, there’s a caution that these sequences are hypotheses rather than proven designs.\nSequence Length and Context: DNA-Diffusion only generates 200 bp sequences in isolation. In reality, an enhancer’s effect might depend on surrounding genomic context or synergy with promoters. Likewise, a 2 kb sequence from DiscDiff might represent a promoter plus some upstream sequence, but it’s still not a full genomic context (AlphaGenome uses 1 Mb context because distal elements can influence genes from far away). So another limitation is contextual integration: how do we place these synthetic sequences into a genome and ensure they work as intended? The DNA-Diffusion team addressed this partly by inserting sequences into known genomic loci and using a model to predict changes. They even found that inserting synthetic enhancers into previously inactive loci could create regulatory activity where there was none, hinting that these sequences can impart function in new locations. However, the outcome might differ if multiple enhancers interact or if repressors in a cell also recognize the sequence. So, the limitation is that generative models currently design sequences in a vacuum. A future goal would be co-designing sequences along with their genomic context or designing larger genomic constructs (like an entire gene with its regulatory domain). Evo 2’s long context might assist here, but diffusion models might need to also scale up to longer ranges or work in tandem with predictive models that account for 3D genome context.\nEvaluation Metrics: Both papers mention the lack of perfect metrics for sequence generation quality. Unlike images where we have FID, or text where we can do human evaluation, for DNA we rely on proxies: k-mer statistics, motif enrichments, predictive model scores. These capture different aspects, but a model could potentially game one metric without truly being optimal (e.g., it could match motif frequency but scramble their order, resulting in non-functional sequence that still “looks” statistically fine). So there’s a limitation in how we measure success. As generative DNA modeling is new, the community is still developing robust benchmarks. DiscDiff’s introduction of S-FID (sequence Frechet Inception Distance using a neural embedding) is one attempt. Over time, more nuanced evaluations, including evolutionary conservation tests (e.g., does a generated human sequence avoid something that would be deleterious, as judged by conservation or mutational constraint data?) or physical property checks (like DNA shape features), might be incorporated. Until then, the limitation is that a model might produce sequences that pass current tests but fail in aspects we didn’t measure.\n\nIn summary, generative diffusion models for DNA are powerful new tools with various possible applications: from designing gene therapies and synthetic organisms, to augmenting data for AI models, to testing biological hypotheses in silico. They are not without limitations – ensuring functional validity and integrating broader context remain challenges – but they mark a significant step toward “Generative Genomics”. By combining these models with advanced predictors (like Enformer or AlphaGenome) and eventually experimental feedback, we move closer to an era of AI-assisted genome engineering, where we can ask for a biological function and have algorithms propose DNA sequences to achieve it. This synergy of generative and predictive models exemplifies the AIVC concept: a virtuous cycle where AI designs and evaluates virtual cell scenarios, accelerating our understanding and creation of biological systems in a safe, controlled manner. The work on DNA-Diffusion and DiscDiff not only provides two distinct perspectives on using diffusion in genomics, but also inspires future research to unify these perspectives – combining the fine control of conditional diffusion with the generality and scale of latent models. As techniques mature, we anticipate diffusion models to play a key role in the “virtual cell” toolbox, generating hypotheses and solutions that human imagination alone might not conceive."
  }
]